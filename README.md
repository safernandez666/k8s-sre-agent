# ğŸš€ K8s SRE/SecOps Agent

ğŸ¤– Agente ReAct (Reason â†’ Act â†’ Observe) para diagnÃ³stico y remediaciÃ³n autÃ³noma
de incidentes en Kubernetes, potenciado por LLM (compatible con Ollama, Kimi, OpenAI, etc.)

## ğŸ—ï¸ Arquitectura

```mermaid
flowchart TB
    subgraph AGENT["ğŸ¤– K8s SRE/SecOps Agent"]
        direction TB
        MONITOR["ğŸ” ClusterMonitor\n<i>Poll cada 30s</i>"]
        DETECT{{"ğŸš¨ Pod unhealthy?\n<i>CrashLoop / OOM / ImagePull</i>"}}
        MONITOR --> DETECT
    end

    subgraph REACT["ğŸ§  ReAct Loop (LLM)"]
        direction TB
        OBSERVE["ğŸ‘ï¸ OBSERVE\n<code>describe_pod</code>\n<code>get_pod_logs</code>\n<code>get_events</code>"]
        REASON["ğŸ¤” REASON\nIdentificar causa raÃ­z"]
        ACT["ğŸ”§ ACT\n<code>delete_pod + kubectl_apply</code>\n<code>patch_resource</code>\n<code>helm_upgrade</code>\n<code>rollout_restart</code>"]
        VERIFY["âœ… VERIFY\n<code>describe_pod</code>\n<code>get_events</code>"]
        FINISH(["ğŸ finish\n<i>resolved: true/false</i>"])
        OBSERVE --> REASON --> ACT --> VERIFY --> FINISH
    end

    subgraph K8S["â˜¸ï¸ Kubernetes Cluster"]
        direction LR
        CP["ğŸ–¥ï¸ srv01\nControl Plane\n<i>192.168.1.100</i>"]
        W1["ğŸ–¥ï¸ srv02\nWorker\n<i>192.168.1.101</i>"]
    end

    subgraph DATA["ğŸ“¡ Data Sources"]
        direction LR
        PROM["ğŸ“Š Prometheus\n<i>MÃ©tricas: CPU, Mem, Restarts</i>"]
        LOKI["ğŸ“œ Loki\n<i>Logs histÃ³ricos (LogQL)</i>"]
    end

    subgraph LLM_PROVIDERS["ğŸ§  LLM Providers"]
        direction LR
        OLLAMA["ğŸ¦™ Ollama\n<i>qwen2.5-coder:7b</i>\n<i>Local, gratis</i>"]
        KIMI["ğŸŒ™ Kimi\n<i>kimi-k2-turbo-preview</i>\n<i>API cloud</i>"]
    end

    DETECT -- "Si" --> REACT
    DETECT -- "No âœ…" --> MONITOR
    REACT <--> |kubectl| K8S
    OBSERVE <--> DATA
    REASON <-.-> LLM_PROVIDERS

    style AGENT fill:#1a1a2e,stroke:#16213e,color:#e0e0e0
    style REACT fill:#0f3460,stroke:#533483,color:#e0e0e0
    style K8S fill:#1b4332,stroke:#2d6a4f,color:#e0e0e0
    style DATA fill:#3a0ca3,stroke:#4361ee,color:#e0e0e0
    style LLM_PROVIDERS fill:#495057,stroke:#6c757d,color:#e0e0e0
    style FINISH fill:#2d6a4f,stroke:#40916c,color:#e0e0e0
    style DETECT fill:#e63946,stroke:#d62828,color:#ffffff
```

## ğŸ“‹ Requisitos

- ğŸ Python 3.10+
- â˜¸ï¸ Kubernetes cluster (kubectl configurado)
- ğŸ¦™ Ollama (para correr el LLM localmente) o API key de Kimi/OpenAI
- ğŸ“œ (Opcional) Loki instalado en el cluster para logs histÃ³ricos
- ğŸ“Š (Opcional) Prometheus instalado para mÃ©tricas

## ğŸš€ InstalaciÃ³n

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/safernandez666/k8s-sre-agent.git
cd k8s-sre-agent
```

### 2ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Instalar Ollama (opciÃ³n local, recomendado)

**ğŸ§ Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**ğŸªŸ Windows:**
Descargar desde: https://ollama.com/download/windows

### 4ï¸âƒ£ Descargar un modelo con Ollama

```bash
# ğŸŒŸ Modelo recomendado (rÃ¡pido y bueno para coding)
ollama pull qwen2.5-coder:7b

# Alternativas:
# ollama pull llama3.2:3b        # MÃ¡s liviano ğŸª¶
# ollama pull codellama:7b       # Especializado en cÃ³digo ğŸ’»
# ollama pull mistral:7b         # Buen balance âš–ï¸
```

### 5ï¸âƒ£ Verificar que Ollama estÃ© corriendo

```bash
ollama list
# DeberÃ­a mostrar el modelo descargado

# Probar el modelo
ollama run qwen2.5-coder:7b "Hola"
```

## âš™ï¸ ConfiguraciÃ³n

EditÃ¡ `config.yaml` con tu configuraciÃ³n:

```yaml
llm:
  ollama:
    api_key: "ollama"                    # Ollama no valida API key
    model: "qwen2.5-coder:7b"
    base_url: "http://localhost:11434/v1"
  kimi:
    api_key: "sk-TU-API-KEY"             # API key de Kimi (moonshot.ai)
    model: "kimi-k2-turbo-preview"
    base_url: "https://api.moonshot.ai/v1"

kubernetes:
  namespace: "monitoring,default,kube-system,prd"
  kubeconfig: null         # null = usa ~/.kube/config

agent:
  poll_interval: 30        # segundos entre ciclos
  auto_remediate: false    # true = actÃºa sin confirmaciÃ³n
  max_iterations: 8        # mÃ¡ximo pasos ReAct
  dry_run: false

loki:
  url: "http://<LOKI_LB_IP>:3100"
  enabled: true            # true = usa logs histÃ³ricos

prometheus:
  url: "http://<PROMETHEUS_LB_IP>:9090"
  enabled: true            # true = usa mÃ©tricas
```

Al iniciar, el agente muestra un menÃº para elegir el proveedor LLM:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Seleccionar proveedor LLM     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1) ollama     (qwen2.5-coder:7b)
â”‚  2) kimi       (moonshot-v1-8k)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ® Uso

```bash
# ğŸ”„ Monitor continuo (selector interactivo de LLM)
python main.py

# ğŸ¯ Elegir LLM directo por CLI
python main.py --llm ollama
python main.py --llm kimi

# ğŸ¤– Monitor continuo autÃ³nomo (sin confirmaciÃ³n)
python main.py --auto

# ğŸ§ª Simular sin ejecutar nada
python main.py --dry-run --auto

# ğŸ¯ Fix directo para un problema especÃ­fico
python main.py --fix "Pod prometheus-grafana en CrashLoopBackOff"

# â–¶ï¸ Un solo ciclo de detecciÃ³n
python main.py --once
```

## ğŸ› ï¸ Herramientas disponibles para el agente

| Herramienta | Tipo | DescripciÃ³n |
|-------------|------|-------------|
| ğŸ‘ï¸ `get_pod_logs` | **Observe** | Logs del contenedor (Ãºltimo crash) |
| ğŸ‘ï¸ `describe_pod` | **Observe** | kubectl describe pod |
| ğŸ‘ï¸ `get_events` | **Observe** | Eventos del namespace/recurso |
| ğŸ‘ï¸ `check_rbac` | **Observe** | Permisos del ServiceAccount |
| ğŸ“œ `query_loki` | **Observe** | Logs histÃ³ricos de Loki (LogQL) |
| ğŸ“œ `search_errors_in_loki` | **Observe** | Busca patrones de error en logs |
| ğŸ“Š `query_prometheus` | **Observe** | Ejecutar queries PromQL |
| ğŸ“Š `get_pod_metrics` | **Observe** | CPU, memoria, restarts de un pod |
| ğŸ“Š `get_high_resource_pods` | **Observe** | Detecta pods con >80% CPU/memoria |
| ğŸ“Š `analyze_pod_health` | **Observe** | AnÃ¡lisis completo de salud del pod |
| ğŸ”§ `delete_pod` | **Act** | Elimina un pod (necesario antes de recrear bare pods) |
| ğŸ”§ `patch_resource` | **Act** | Patch merge a Deployments/StatefulSets |
| ğŸ”§ `helm_upgrade` | **Act** | Modifica valores del chart |
| ğŸ”§ `kubectl_apply` | **Act** | Aplica manifest YAML (crear/recrear pods, RBAC, etc) |
| ğŸ”§ `rollout_restart` | **Act** | Reinicio graceful de deployment |
| ğŸ `finish` | **Terminate** | Cierra el loop con resultado |

### ğŸ“ Ejemplos de consultas Loki

El agente puede usar LogQL para obtener contexto histÃ³rico:

```logql
# Logs de los Ãºltimos 24 horas
{namespace="monitoring", pod=~"grafana.*"}

# Buscar errores en el Ãºltimo dÃ­a
{namespace="default"} |= "error"

# Logs de mÃºltiples pods simultÃ¡neamente
{namespace="kube-system", pod=~"calico.*"}
```

### ğŸ“Š Ejemplos de consultas Prometheus

El agente puede usar PromQL para obtener mÃ©tricas:

```promql
# Uso de CPU por pod
rate(container_cpu_usage_seconds_total{namespace="monitoring"}[5m])

# Uso de memoria
container_memory_usage_bytes{namespace="monitoring"}

# Restarts de contenedores
kube_pod_container_status_restarts_total{namespace="monitoring"}

# Pods con alta utilizaciÃ³n de CPU
rate(container_cpu_usage_seconds_total[5m]) > 0.8
```

## ğŸ“œ IntegraciÃ³n con Loki + Grafana (Opcional pero recomendado)

Para que el agente tenga acceso a logs histÃ³ricos:

### 1ï¸âƒ£ Instalar Loki

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm upgrade --install loki grafana/loki-stack \
  --namespace monitoring \
  --set promtail.enabled=true
```

### 2ï¸âƒ£ Exponer Grafana con Ingress

```bash
# Aplicar configuraciÃ³n de MetalLB + Ingress
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.6/deploy/static/provider/cloud/deploy.yaml

# Configurar Ingress para Grafana
kubectl apply -f loki-datasource.yaml  # Ver archivo en repo
```

### 3ï¸âƒ£ Configurar /etc/hosts

```
192.168.1.240   grafana.local
```

Acceder a: http://grafana.local

## ğŸ“Š IntegraciÃ³n con Prometheus (Opcional pero recomendado)

Para que el agente tenga acceso a mÃ©tricas:

### 1ï¸âƒ£ Instalar Prometheus

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring
```

### 2ï¸âƒ£ Exponer Prometheus y Loki con LoadBalancer

Para que el agente (corriendo fuera del cluster) pueda alcanzar los servicios:

```yaml
# srv-monitoring.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-lb
  namespace: monitoring
spec:
  type: LoadBalancer
  selector:
    app: loki
  ports:
  - port: 3100
    targetPort: 3100
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus-lb
  namespace: monitoring
spec:
  type: LoadBalancer
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
```

```bash
kubectl apply -f srv-monitoring.yaml
# Verificar las IPs asignadas por MetalLB
kubectl get svc -n monitoring loki-lb prometheus-lb
```

Luego actualizar `config.yaml` con las IPs asignadas.

### 3ï¸âƒ£ Agregar Prometheus como Data Source en Grafana

| Campo | Valor |
|-------|-------|
| Name | `Prometheus` |
| URL | `http://prometheus-kube-prometheus-prometheus:9090` |
| Access | Server (default) |

## ğŸ—ºï¸ Roadmap

```
v0.1 (actual) âœ…
â”œâ”€â”€ ğŸ¤– ReAct sobre kubectl
â”œâ”€â”€ ğŸš¨ DetecciÃ³n de CrashLoop / OOMKill / ImagePull
â”œâ”€â”€ ğŸ”§ Fix de RBAC, Helm, manifests
â”œâ”€â”€ ğŸ“œ IntegraciÃ³n Loki para logs histÃ³ricos âœ…
â””â”€â”€ ğŸ“Š IntegraciÃ³n Prometheus para mÃ©tricas âœ…

v0.2 (prÃ³ximo)
â”œâ”€â”€ ğŸ”’ IntegraciÃ³n Wazuh (alertas EDR)
â”œâ”€â”€ ğŸ’¾ Memoria de incidentes (SQLite)
â”œâ”€â”€ ğŸ“¢ Notificaciones (Slack/webhook)
â””â”€â”€ ğŸ“ˆ Dashboard web de incidentes

v0.3
â”œâ”€â”€ ğŸ‘¤ GestiÃ³n de identidades (IAM)
â”œâ”€â”€ ğŸ”— CorrelaciÃ³n usuario â†’ alerta â†’ pod
â””â”€â”€ ğŸ›¡ï¸ MITRE ATT&CK mapping
```

## ğŸ› Troubleshooting

### ğŸ¦™ Ollama no responde

```bash
# Verificar que ollama estÃ© corriendo
curl http://localhost:11434/api/tags

# Reiniciar ollama
ollama serve
```

### â˜¸ï¸ El agente no encuentra el cluster

```bash
# Verificar kubectl
kubectl get nodes

# Especificar kubeconfig en config.yaml
kubernetes:
  kubeconfig: "/ruta/a/tu/config"
```

### ğŸ“œ Loki no conecta

```bash
# Verificar que Loki estÃ© corriendo
kubectl get pods -n monitoring | grep loki

# Probar desde el pod de Grafana
kubectl exec -it -n monitoring deployment/prometheus-grafana -- \
  wget -qO- http://loki.monitoring.svc.cluster.local:3100/ready
```

### ğŸ“Š Prometheus no conecta

```bash
# Verificar que Prometheus estÃ© corriendo
kubectl get pods -n monitoring | grep prometheus

# Verificar servicios LoadBalancer
kubectl get svc -n monitoring loki-lb prometheus-lb

# Probar conectividad desde fuera del cluster
curl http://<PROMETHEUS_LB_IP>:9090/api/v1/status/buildinfo
curl http://<LOKI_LB_IP>:3100/ready
```

## ğŸ“„ Licencia

ğŸ“ MIT
